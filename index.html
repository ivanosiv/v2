<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>App Nutrição Live</title>
  <!-- Ícones e Material Design -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">
  <script defer src="https://code.getmdl.io/1.3.0/material.min.js"></script>
  
  <style>
    body {
      font-family: 'Roboto', sans-serif;
      background-color: #f7f7f7;
      margin: 0;
      padding: 0;
    }
    
    .mdl-layout {
      min-height: 100vh;
    }
    
    .mdl-layout__header {
      background-color: #4CAF50; /* Verde para saúde/nutrição */
    }
    
    .mdl-layout__header .mdl-layout-title {
      font-size: 24px;
      font-weight: 500;
    }
    
    .demo-content {
      padding: 20px;
      display: flex;
      flex-direction: column;
      align-items: center;
      background-color: #ffffff;
      margin: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    
    .button-group {
      margin-bottom: 20px;
    }
    
    #videoElement {
      width: 320px;
      height: 240px;
      border-radius: 8px;
      background-color: #000;
    }
    
    #canvasElement {
      display: none;
    }
    
    #chatLog {
      width: 100%;
      max-width: 640px;
      margin-top: 20px;
      padding: 10px;
      border: 1px solid #ddd;
      border-radius: 4px;
      background: #fafafa;
      height: 200px;
      overflow-y: auto;
    }
  </style>
</head>

<body>
  <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
    <header class="mdl-layout__header">
      <div class="mdl-layout__header-row">
        <!-- Título do App -->
        <span class="mdl-layout-title">App Nutrição Live</span>
      </div>
    </header>
    <main class="mdl-layout__content">
      <div class="page-content">
        <div class="demo-content">
          <!-- Botões para Controle de Voz -->
          <div class="button-group">
            <button id="startButton"
              class="mdl-button mdl-js-button mdl-button--fab mdl-button--mini-fab mdl-button--colored">
              <i class="material-icons">mic</i>
            </button>
            <button id="stopButton"
              class="mdl-button mdl-js-button mdl-button--fab mdl-button--mini-fab">
              <i class="material-icons">mic_off</i>
            </button>
          </div>

          <!-- Elemento de Vídeo para Captura da Webcam -->
          <video id="videoElement" autoplay></video>

          <!-- Canvas Oculto para Captura de Imagens -->
          <canvas id="canvasElement"></canvas>

          <!-- Área para Exibir Mensagens do Chat -->
          <div id="chatLog"></div>
        </div>
      </div>
    </main>
  </div>

  <script defer>
    const URL = "ws://localhost:9082";
    const video = document.getElementById("videoElement");
    const canvas = document.getElementById("canvasElement");
    const context = canvas.getContext("2d");
    const startButton = document.getElementById('startButton');
    const stopButton = document.getElementById('stopButton');
    let stream = null;
    let currentFrameB64;
    let webSocket = null;
    let audioContext = null;
    let mediaRecorder = null;
    let processor = null;
    let pcmData = [];
    let interval = null;
    let initialized = false;
    let audioInputContext;
    let workletNode;

    // Inicia a webcam
    async function startWebcam() {
      try {
        const constraints = {
          video: {
            width: { max: 640 },
            height: { max: 480 },
          },
        };
        stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
      } catch (err) {
        console.error("Erro ao acessar a webcam: ", err);
      }
    }

    // Captura imagem do vídeo e converte para base64
    function captureImage() {
      if (stream) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        const imageData = canvas.toDataURL("image/jpeg").split(",")[1].trim();
        currentFrameB64 = imageData;
      }
    }

    window.addEventListener("load", async () => {
      await startWebcam();
      setInterval(captureImage, 3000);
      connect();
    });

    function connect() {
      console.log("Conectando a: ", URL);
      webSocket = new WebSocket(URL);
      webSocket.onclose = (event) => {
        console.log("WebSocket fechado: ", event);
        alert("Conexão encerrada");
      };
      webSocket.onerror = (event) => {
        console.log("Erro no WebSocket: ", event);
      };
      webSocket.onopen = (event) => {
        console.log("WebSocket aberto: ", event);
        sendInitialSetupMessage();
      };
      webSocket.onmessage = receiveMessage;
    }

    function sendInitialSetupMessage() {
      console.log("Enviando mensagem de setup");
      const setupMessage = {
        setup: {
          generation_config: { response_modalities: ["AUDIO"] },
        },
      };
      webSocket.send(JSON.stringify(setupMessage));
    }

    function sendVoiceMessage(b64PCM) {
      if (webSocket == null) {
        console.log("WebSocket não inicializado");
        return;
      }
      const payload = {
        realtime_input: {
          media_chunks: [
            { mime_type: "audio/pcm", data: b64PCM },
            { mime_type: "image/jpeg", data: currentFrameB64 },
          ],
        },
      };
      webSocket.send(JSON.stringify(payload));
      console.log("Enviado: ", payload);
    }

    function receiveMessage(event) {
      const messageData = JSON.parse(event.data);
      const response = new Response(messageData);
      if (response.text) {
        displayMessage("APP NUTRIÇÃO: " + response.text);
      }
      if (response.audioData) {
        injestAudioChunkToPlay(response.audioData);
      }
    }

    async function initializeAudioContext() {
      if (initialized) return;
      audioInputContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
      await audioInputContext.audioWorklet.addModule("pcm-processor.js");
      workletNode = new AudioWorkletNode(audioInputContext, "pcm-processor");
      workletNode.connect(audioInputContext.destination);
      initialized = true;
    }

    function base64ToArrayBuffer(base64) {
      const binaryString = window.atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    }

    function convertPCM16LEToFloat32(pcmData) {
      const inputArray = new Int16Array(pcmData);
      const float32Array = new Float32Array(inputArray.length);
      for (let i = 0; i < inputArray.length; i++) {
        float32Array[i] = inputArray[i] / 32768;
      }
      return float32Array;
    }

    async function injestAudioChunkToPlay(base64AudioChunk) {
      try {
        if (!initialized) {
          await initializeAudioContext();
        }
        if (audioInputContext.state === "suspended") {
          await audioInputContext.resume();
        }
        const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
        const float32Data = convertPCM16LEToFloat32(arrayBuffer);
        workletNode.port.postMessage(float32Data);
      } catch (error) {
        console.error("Erro ao processar áudio: ", error);
      }
    }

    function recordChunk() {
      const buffer = new ArrayBuffer(pcmData.length * 2);
      const view = new DataView(buffer);
      pcmData.forEach((value, index) => {
        view.setInt16(index * 2, value, true);
      });
      const base64 = btoa(String.fromCharCode.apply(null, new Uint8Array(buffer)));
      sendVoiceMessage(base64);
      pcmData = [];
    }

    async function startAudioInput() {
      audioContext = new AudioContext({ sampleRate: 16000 });
      const stream = await navigator.mediaDevices.getUserMedia({ audio: { channelCount: 1, sampleRate: 16000 } });
      const source = audioContext.createMediaStreamSource(stream);
      processor = audioContext.createScriptProcessor(4096, 1, 1);
      processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0);
        const pcm16 = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          pcm16[i] = inputData[i] * 0x7fff;
        }
        pcmData.push(...pcm16);
      };
      source.connect(processor);
      processor.connect(audioContext.destination);
      interval = setInterval(recordChunk, 3000);
    }

    function stopAudioInput() {
      if (processor) {
        processor.disconnect();
      }
      if (audioContext) {
        audioContext.close();
      }
      clearInterval(interval);
    }

    function displayMessage(message) {
      console.log(message);
      addParagraphToDiv("chatLog", message);
    }

    function addParagraphToDiv(divId, text) {
      const newParagraph = document.createElement("p");
      newParagraph.textContent = text;
      const div = document.getElementById(divId);
      div.appendChild(newParagraph);
    }

    startButton.addEventListener('click', startAudioInput);
    stopButton.addEventListener('click', stopAudioInput);

    class Response {
      constructor(data) {
        this.text = data.text || null;
        this.audioData = data.audio || null;
        this.endOfTurn = data.endOfTurn || null;
      }
    }
  </script>
</body>

</html>
